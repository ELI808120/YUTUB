import urllib.request
import re
import json
import time
import random

def get_channel_videos(channel_id):
    rss_url = f"https://www.youtube.com/feeds/videos.xml?channel_id={channel_id}"
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        req = urllib.request.Request(rss_url, headers=headers)
        with urllib.request.urlopen(req, timeout=10) as res:
            content = res.read().decode('utf-8')
            video_ids = re.findall(r'<yt:videoId>(.*?)</yt:videoId>', content)
            titles = re.findall(r'<title>(.*?)</title>', content)[1:]
            return [{"id": v, "title": t.replace('"', "'")} for v, t in zip(video_ids, titles)]
    except:
        return []

def run():
    print("ğŸš€ ×× ×•×¢ ×¡×¨×™×§×” ×•×™×¨××œ×™ ×”×•×¤×¢×œ - ××—×¤×© ×”×××•×•×•×•×Ÿ ×¡×¨×˜×•× ×™×...")
    
    try:
        with open('final_history_final.json', 'r', encoding='utf-8') as f:
            history = json.load(f)
    except: return

    try:
        with open('pending_check.json', 'r', encoding='utf-8') as f:
            new_candidates = json.load(f)
    except:
        new_candidates = []

    seen = {v['id'] for v in history}
    pending_ids = {v['id'] for v in new_candidates}

    # ×“×•×’× 40 ×¡×¨×˜×•× ×™× ××”×”×™×¡×˜×•×¨×™×” ×›× ×§×•×“×•×ª ××•×¦×
    sample_size = min(len(history), 40)
    random_samples = random.sample(history, sample_size)

    for entry in random_samples:
        print(f"ğŸ” ×¡×•×¨×§ ×¢×•××§ ×•×”××œ×¦×•×ª: {entry['title'][:40]}...")
        try:
            url = f"https://www.youtube.com/watch?v={entry['id']}"
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=10) as res:
                html = res.read().decode('utf-8', errors='ignore')
                
                # 1. ×—×™×œ×•×¥ ×”××•×Ÿ ×”××œ×¦×•×ª (×¢×“ 40 ××›×œ ×“×£)
                recommended = re.findall(r'"videoId":"([a-zA-Z0-9_-]{11})"', html)
                for r_id in recommended[:40]: 
                    if r_id not in seen and r_id not in pending_ids:
                        new_candidates.append({"id": r_id, "title": "×¡×¨×˜×•×Ÿ ××•××œ×¥ (×—×“×©)"})
                        pending_ids.add(r_id)

                # 2. ×—×™×œ×•×¥ ×¢×¨×•×¦×™× ××•××œ×¦×™× ×•×¡×¨×™×§×ª ×”-RSS ×©×œ×”×
                # ×–×” ×’×•×¨× ×œ×¡×•×¨×§ "×œ×§×¤×•×¥" ×œ×¢×¨×•×¦×™× ×“×•××™×
                extra_channels = re.findall(r'"channelId":"(UC[a-zA-Z0-9_-]{22})"', html)
                for ex_cid in list(set(extra_channels))[:3]: 
                    ex_videos = get_channel_videos(ex_cid)
                    for ev in ex_videos:
                        if ev['id'] not in seen and ev['id'] not in pending_ids:
                            print(f"   âœ¨ ××¦××ª×™ ×¢×¨×•×¥ ×—×“×© ×•×¡×¨×˜×•×Ÿ: {ev['title'][:30]}")
                            new_candidates.append(ev)
                            pending_ids.add(ev['id'])
                            
        except Exception as e:
            continue
        
        # ××›×¡×” ×’×‘×•×”×” ×××•×“ ×›×“×™ ×©×ª×§×‘×œ "×”×¨×‘×” ×××© ×”×¨×‘×”"
        if len(new_candidates) > 500: 
            print("ğŸ”¥ ×”×’×¢× ×• ×œ××¢×œ 500 ×¡×¨×˜×•× ×™×! ×¢×•×¦×¨×™×.")
            break
        
        time.sleep(0.1)

    with open('pending_check.json', 'w', encoding='utf-8') as f:
        json.dump(new_candidates, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… ×¡×™×•×! ×‘×ª×•×¨ ××—×›×™× ×›×¨×’×¢ {len(new_candidates)} ×¡×¨×˜×•× ×™× ×œ×‘×“×™×§×ª ×”-AAA ×©×œ×š.")

if __name__ == "__main__":
    run()
